{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1857c176-0e13-4fac-964d-dfa95993ae49",
   "metadata": {},
   "source": [
    "# `pack_data.ipynb`\n",
    "\n",
    "* Takes the raw data and unwraps the dict structure to efficiently have all trajectory data in a bunch of NumPy arrays.\n",
    "* Running the entire notebook will produce a file `data_packed.npz`. If $N$ is the *total* number of trajectories, with $L$ labels and $P$ trajectory variables:\n",
    "    * names of the variables stored as trajectory data (`sq_disp` etc.) are stored in `data_names`, length $P$\n",
    "    * likewise names of the structure parameters to be predicted (`lattice_type` etc.) are stored in `label_names`, length $L$\n",
    "    * `labels` is an array of shape $(L,N)$ that stores structure parameters for each data point\n",
    "    * `traj_data` is an array of shape $(P, \\sum n)$ where $\\sum n$ is the *total number of points in all trajectories combined*... basically the variable-length trajectories are\n",
    "    * `config_indices` is an array of length $N$ that tracks the disorder configuration that each trajectory came from. Note that these are *not* globally unique! Only guaranteed to be unique within a single set of lattice parameters\n",
    "* So basically you get trajectory `i` by indexing `traj_data[:,offsets[i]:offsets[i+1]]`, and the lattice parameters are `labels[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941bcd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d15b70-6012-40af-b202-5a6d78b3daae",
   "metadata": {},
   "source": [
    "# Loading and prep work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae982d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(lattice_type, dilution, hopping_type):\n",
    "    if hopping_type == 'nn':\n",
    "        hopping_type = 'nearestneighbor'\n",
    "    elif hopping_type == 'lr':\n",
    "        hopping_type = 'alpha=6'\n",
    "    return np.load(f\"Data/{lattice_type}_p={dilution}%_{hopping_type}.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49a676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzs = {}\n",
    "# produces a dict where the key is (lattice_type: str, alpha: int, lr_hopping: bool)\n",
    "for filename in glob.glob('Data/*.npz'):\n",
    "    lattice_type, p, hopping_type = filename[5:-4].split('_')\n",
    "    p = int(p[2:-1])\n",
    "    npzs[(lattice_type, p, (hopping_type == 'alpha=6'))] = np.load(filename, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6377dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATTICE_NAMES = ['SC', 'BCC', 'FCC', 'diamond']\n",
    "LATTICE_TYPE_LOOKUP = {name:i for i, name in enumerate(LATTICE_NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0eb2076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_TESTPOINT = True\n",
    "if LOAD_TESTPOINT:\n",
    "    testdata = load_npz('FCC', 75, 'nn')\n",
    "    testres = testdata['results']\n",
    "    testpoint = testres[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50610a9",
   "metadata": {},
   "source": [
    "Note to self:\n",
    "* fields of a NPZ are: `['results', 'size', 'a', 'lattice_type', 'diluted', 'prob', 'nearest_neighbor', 'A', 'alpha', 't_max', 'n_trajectories', 'n_configs']`\n",
    "* fields of the results file are: `['wait_times', 'jump_lengths', 'times', 'sq_disp', 'distinct_sites', 'sites']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79532cf2-d796-4166-aff2-ecea96da050c",
   "metadata": {},
   "source": [
    "This iterates over all `.npz` files twice: once to do some basic analysis of sizes involved, thus allowing preallocation of the array... this has the nice effect of avoiding Python list overhead but it does take like an extra minute... if data size hasn't changed, here are the precomputed numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49706eb-f5c4-457e-a44f-dd33b42e952f",
   "metadata": {},
   "source": [
    "# Simple analytics / precomputing sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c45adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PRECOMPUTED = True\n",
    "if not USE_PRECOMPUTED:\n",
    "    tot_size = 0\n",
    "    traj_lengths = []\n",
    "    tot_times = []\n",
    "    tot_n_traj = 0\n",
    "    for _, data in tqdm(npzs.items()):\n",
    "        res = data['results']\n",
    "        tot_n_traj += len(res)\n",
    "        tot_size += sum(np.array(point['sq_disp']).nbytes for point in res)\n",
    "        traj_lengths.extend([len(point['sq_disp']) for point in res])\n",
    "        tot_times.extend([point['times'][-1] for point in res])\n",
    "    tot_times = np.array(tot_times)\n",
    "    traj_lengths = np.array(traj_lengths)\n",
    "    tot_n_traj_points = sum(traj_lengths)\n",
    "    print(f\"total data size {tot_size/1e6:.2f} MB\")\n",
    "else:  # avoid iteration; obvs remember to update if data changes\n",
    "    tot_n_traj_points = 65082776\n",
    "    tot_n_traj = 320000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62cecde8-2eba-4c43-9aeb-a16a02e8437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_traj: 320000\n",
      "sum of lengths: 65082776\n"
     ]
    }
   ],
   "source": [
    "print(f\"n_traj: {tot_n_traj}\\nsum of lengths: {tot_n_traj_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a402e46-967b-4bae-bc23-3807ade1b660",
   "metadata": {},
   "source": [
    "# Packing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38942f7-6a5b-425c-966e-71f65b6b534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3030f7cce5ff4015a800f9b3c9c8a66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traj_data = np.zeros((6, tot_n_traj_points))\n",
    "offsets = np.zeros(tot_n_traj+1, dtype=int)\n",
    "labels = np.zeros((tot_n_traj, 3), dtype=int)\n",
    "config_indices = np.zeros(tot_n_traj+1, dtype=int)\n",
    "offsets[-1] = tot_n_traj_points\n",
    "\n",
    "point_offset = 0\n",
    "traj_offset = 0\n",
    "\n",
    "for (lat, p, is_lr), data in tqdm(npzs.items()):\n",
    "    res = data['results']\n",
    "    label = [LATTICE_TYPE_LOOKUP[lat], p, int(is_lr)]\n",
    "    for i, point in enumerate(res):\n",
    "        n_steps = len(point['sq_disp'])\n",
    "        labels[point_offset,:] = label\n",
    "        offsets[point_offset] = traj_offset\n",
    "        if label[1] < 100:\n",
    "            config_indices[point_offset] = int(i // 1000)\n",
    "        else:\n",
    "            config_indices[point_offset] = 0\n",
    "\n",
    "        end = traj_offset + n_steps\n",
    "\n",
    "        for i, key in enumerate(('wait_times', 'jump_lengths')):\n",
    "            traj_data[i,traj_offset+1:end] = point[key]\n",
    "        for i, key in enumerate(('times', 'sq_disp', 'distinct_sites', 'sites')):\n",
    "            traj_data[i+2,traj_offset:end] = point[key]\n",
    "\n",
    "        point_offset += 1\n",
    "        traj_offset += n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22791bd1-8316-44cf-86f3-d06943d74de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = ['wait_times', 'jump_lengths', 'times', 'sq_disp', 'distinct_sites', 'sites']\n",
    "label_names = ['lattice_type', 'p', 'is_lr']\n",
    "np.savez(\n",
    "    'data_packed.npz',\n",
    "    data_names=data_names,\n",
    "    label_names=label_names,np.int64(501248), np.int64(501249), np.int64(500224), np.int64(500225), np.int64(500226), np.int64(500227), np.int64(500228), np.int64(500229), np.int64(11270), np.int64(11271), np.int64(11272), np.int64(11273), np.int64(11274), np.int64(11275), np.int64(11276), np.int64(11277), np.int64(11278), np.int64(11279), np.int64(11300), np.int64(11301), np.int64(11302), np.int64(11303), np.int64(1001000), np.int64(11304), np.int64(11305), np.int64(11306), np.int64(11307), np.int64(11308), np.int64(11309), np.int64(11610), np.int64(11611), np.int64(250350), np.int64(11612), np.int64(250351), np.int64(11613), np.int64(250352), np.int64(1000000), np.int64(11614), np.int64(250353), np.int64(11615), np.int64(250354), np.int64(11616), np.int64(250355), np.int64(11617), np.int64(250356), np.int64(11618), np.int64(250357), np.int64(11619), np.int64(250358), np.int64(11360), np.int64(11361), np.int64(11362), np.int64(250359), np.int64(11363), np.int64(11364), np.int64(11365), np.int64(11366), np.int64(11367), np.int64(11368), np.int64(11369), np.int64(250360), np.int64(250361), np.int64(800370), np.int64(800371), np.int64(800372), np.int64(800373), np.int64(800374), np.int64(800375), np.int64(800376), np.int64(800377), np.int64(800378), np.int64(800379), np.int64(750200), np.int64(750201), np.int64(750202), np.int64(750203), np.int64(750204), np.int64(750205), np.int64(750206), np.int64(750207), np.int64(750208), np.int64(750209), np.int64(250365), np.int64(250366), np.int64(250367), np.int64(1001100), np.int64(250368), np.int64(250369), np.int64(1000100), np.int64(750250), np.int64(750251), np.int64(750252), np.int64(750253), np.int64(750254), np.int64(750255), np.int64(750256), np.int64(750257), np.int64(750258), np.int64(750259), np.int64(400590), np.int64(400591), np.int64(400592), np.int64(400593), np.int64(400594), np.int64(400595), np.int64(400596), np.int64(400597), np.int64(400598), np.int64(400599), np.int64(250364), np.int64(500221), np.int64(300270), np.int64(1001200), np.int64(300271), np.int64(501490), np.int64(501491), np.int64(501492), np.int64(501493), np.int64(501494), np.int64(501495), np.int64(501496), np.int64(501497), np.int64(501498), np.int64(501499), np.int64(500220), np.int64(300276), np.int64(300277),\n",
    "    lattice_names=LATTICE_NAMES,\n",
    "    offsets=offsets,\n",
    "    labels=labels,\n",
    "    traj_data=traj_data,\n",
    "    config_indices=config_indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabe61f-ef17-4421-9399-cbe4e90b78f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
